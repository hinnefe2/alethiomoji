{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An alethiometer for the modern age\n",
    "\n",
    "*The Golden Compass* was one of my favorite books growing up. It has lots of your standard young adult fantasy epic elements -- a plucky heroine, talking animals, authoritarian villians -- but it also touches on some weighty theological themes. The author described it as a deliberate inversion of Milton's *Paradise Lost* (and not for nothing, at the end of the series the protagonists save the world by killing God and re-committing original sin). \n",
    "A central element in the book is the existence of the eponymous \"golden compass\", a literal *machina qua deus ex* which answers questions through divine intervention. The compass presents its answers as a series of ideograms: its face is ringed with symbols and when posed a question its needle sweeps around the face selecting the symbols which comprise the answer. I always wanted one of those when I was a kid but, alas, back then powerful artifacts with oracular capabilities were in short supply. Nowadays we have smartphones and twitter though so better late than never! In this post I'm going to describe a twitter bot I made which answers questions with emoji (hence [*alethiomoji*](https://github.com/hinnefe2/alethiomoji), the name of the project; the golden compass was also called an alethiometer). This is where we're headed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/alethiomoji\">@alethiomoji</a> is this the end of the the world?</p>&mdash; Henry Hinnefeld (@DrJSomeday) <a href=\"https://twitter.com/DrJSomeday/status/824076525817491456\">January 25, 2017</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"und\" dir=\"ltr\"><a href=\"https://twitter.com/DrJSomeday\">@DrJSomeday</a> üîö üåê ‚è≥</p>&mdash; Emoji Golden Compass (@alethiomoji) <a href=\"https://twitter.com/alethiomoji/status/824076719292317698\">January 25, 2017</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot has three main parts:\n",
    "\n",
    "1. A sentence parser which pulls out semantically important words.\n",
    "2. A matching algorithm which finds emoji that are related to a given word.\n",
    "3. Some machinery to read from and post to twitter.\n",
    "\n",
    "Note that bot doesn't actually try to 'answer' the question in any meaningful way: under the hood it's just finding emoji which are related to the important words in the question and then adding in an extra emoji that can be interpreted as a yes / no / maybe.\n",
    "\n",
    "I used existing python modules for parts 1 ([stat_parser](https://github.com/emilmont/pyStatParser)) and 3 ([twython](https://twython.readthedocs.io/en/latest/)), so here we'll focus on part 2.\n",
    "\n",
    "\n",
    "### Matching words to emoji\n",
    "\n",
    "The task at hand is to come up with an algorithm which finds one or more emoji which are related to a given word.\n",
    "One place to start is with the [official descriptions](http://unicode.org/emoji/charts/full-emoji-list.html) of each emoji. Conveniently for us, the folks at [emojityper.com](https://emojityper.com/) have already scraped all the descriptions into a nice, tidy csv [file](https://github.com/emojityper/emojityper.github.io/blob/master/res/emoji/annotations.txt).\n",
    "\n",
    "As a first attempt, we'll start by counting how many times To do the actual word counting we'll use scikit learn's CountVectorizer, which exists for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiling</th>\n",
       "      <th>tears</th>\n",
       "      <th>grinning</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unicode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>üòÄ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GRINNING FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÅ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GRINNING FACE WITH SMILING EYES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÇ</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÉ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SMILING FACE WITH OPEN MOUTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÑ</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SMILING FACE WITH OPEN MOUTH AND SMILING EYES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         smiling  tears  grinning  \\\n",
       "unicode                             \n",
       "üòÄ              0      0         1   \n",
       "üòÅ              1      0         1   \n",
       "üòÇ              0      1         0   \n",
       "üòÉ              1      0         0   \n",
       "üòÑ              2      0         0   \n",
       "\n",
       "                                           description  \n",
       "unicode                                                 \n",
       "üòÄ                                        GRINNING FACE  \n",
       "üòÅ                      GRINNING FACE WITH SMILING EYES  \n",
       "üòÇ                               FACE WITH TEARS OF JOY  \n",
       "üòÉ                         SMILING FACE WITH OPEN MOUTH  \n",
       "üòÑ        SMILING FACE WITH OPEN MOUTH AND SMILING EYES  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "annot = pd.read_csv('cleaned_annotations.txt', index_col='unicode')\n",
    "vectorizer = CountVectorizer().fit(annot.description)\n",
    "\n",
    "# CountVectorizer returns a numpy array of the word count values,\n",
    "# here we're turning that into a nicely labelled pandas DataFrame\n",
    "def get_count_df(cv, series):\n",
    "    vals = cv.transform(series)\n",
    "    cols = sorted(cv.vocabulary_, key=cv.vocabulary_.get, reverse=False)\n",
    "    idx = series.index\n",
    "    return pd.DataFrame(data=vals.toarray(), columns=cols, index=idx)\n",
    "\n",
    "df = get_count_df(vectorizer, annot.description)\n",
    "\n",
    "# display a small subset of the DataFrame\n",
    "df.iloc[:5][['smiling','tears','grinning']].join(annot['description'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'dog'\n",
    "word_vec = get_count_df(vectorizer, pd.Series(word, name=word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unicode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>üêï</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üê∂</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üå≠</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÄ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üì§</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "unicode   \n",
       "üêï        1\n",
       "üê∂        1\n",
       "üå≠        1\n",
       "üòÄ        0\n",
       "üì§        0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = df.dot(word_vec.transpose())\n",
    "matches.sort_values(0,ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works pretty well for words which show up in the official emoji descriptions, however there are only about 1500 different words used in the descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more mathematical terms, we're trying to map elements of one set (words) onto elements of a different set (emoji). To do this I'm going to embed all my elements (words and emoji) in the same vector space, and then see which elements are close to each other in that space. \n",
    "\n",
    "That's a bit abstract though, so let's get a little more concrete: what I'm trying to do here is assign each word and each emoji a series of numbers which somehow describe the word/emoji. Then, to find an emoji which matches a given word, I search for the emoji which has numbers that are similar to those of the supplied word. \n",
    "\n",
    "For example, suppose I have the following emoji descriptions:\n",
    "\n",
    "    ‚ù§Ô∏è: HEART\n",
    "    üòç: HEART FACE\n",
    "    üòÉ: FACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can assign each emoji a series of numbers (i.e. a vector) by counting how many times each word shows up in its description, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEART</th>\n",
       "      <th>FACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>‚ù§Ô∏è</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòç</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÉ</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HEART  FACE\n",
       "‚ù§Ô∏è      1     0\n",
       "üòç       1     1\n",
       "üòÉ       0     1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create vectors for each emoji by counting the occurrence of each word in its description\n",
    "df = pd.DataFrame(data=[[1, 0], [1, 1], [0, 1]], \n",
    "                  index=['‚ù§Ô∏è', 'üòç', 'üòÉ'],\n",
    "                  columns=['HEART', 'FACE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to find emoji which match the word 'heart' I assign the word 'heart' a vector in the same way, and compare its vector to those of all the emoji using the dot product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEART</th>\n",
       "      <th>FACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>heart</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HEART  FACE\n",
       "heart      1     0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a vector for the word 'heart' the same way as we did for the emoji\n",
    "heart_word = pd.DataFrame(data=[[1, 0]], \n",
    "                          index=['heart'], \n",
    "                          columns=['HEART', 'FACE'])\n",
    "heart_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>‚ù§Ô∏è</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòç</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÉ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    heart\n",
       "‚ù§Ô∏è      1\n",
       "üòç       1\n",
       "üòÉ       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the vector for the word 'heart' to the emoji vectors using the dot product\n",
    "df.dot(heart_word.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values we end up with tell us how similar the word 'heart' is to each of our emoji. According to this, we've matched the word 'heart' to the emojis ‚ù§Ô∏è and üòç but not to üòÉ.\n",
    "\n",
    "This is the main idea behind each of the more detailed algorithms described below: \n",
    "- Assign each emoji a series of numbers (i.e. a vector).\n",
    "- When given a word to match, assign it a vector in the same way.\n",
    "- Compare the vector for the given word with the vectors for all the emoji.\n",
    "\n",
    "The trick is coming up with a good way to assign vectors. Below I'll describe two different methods I used in the bot: the first is a slightly improved version of the example above, and the second uses [word2vec](https://en.wikipedia.org/wiki/Word2vec).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning vectors using emoji descriptions\n",
    "\n",
    "One place to start is with the [official descriptions](http://unicode.org/emoji/charts/full-emoji-list.html) of each emoji. Conveniently for us, the folks at [emojityper.com](https://emojityper.com/) have already scraped all the descriptions into a nice, tidy csv [file](https://github.com/emojityper/emojityper.github.io/blob/master/res/emoji/annotations.txt).\n",
    "To do the actual word counting we'll use scikit learn's CountVectorizer, which exists for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiling</th>\n",
       "      <th>kissing</th>\n",
       "      <th>grinning</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unicode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>üòÄ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÅ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÇ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÉ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÑ</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         smiling  kissing  grinning\n",
       "unicode                            \n",
       "üòÄ              0        0         1\n",
       "üòÅ              1        0         1\n",
       "üòÇ              0        0         0\n",
       "üòÉ              1        0         0\n",
       "üòÑ              2        0         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "annot = pd.read_csv('cleaned_annotations.txt', index_col='unicode')\n",
    "vectorizer = CountVectorizer().fit(annot.description)\n",
    "\n",
    "# CountVectorizer returns a numpy array of the word count values,\n",
    "# here we're turning that into a nicely labelled pandas DataFrame\n",
    "def get_count_df(cv, series):\n",
    "    vals = cv.transform(series)\n",
    "    cols = sorted(cv.vocabulary_, key=cv.vocabulary_.get, reverse=False)\n",
    "    idx = series.index\n",
    "    return pd.DataFrame(data=vals.toarray(), columns=cols, index=idx)\n",
    "\n",
    "df = get_count_df(vectorizer, annot.description)\n",
    "\n",
    "# display a small subset of the DataFrame\n",
    "df.iloc[:5][['smiling','kissing','grinning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = 'cake'\n",
    "word_vec = get_count_df(vectorizer, pd.Series(word, name=word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unicode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>üç•</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üéÇ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÄ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíµ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üìß</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "unicode   \n",
       "üç•        2\n",
       "üéÇ        1\n",
       "üòÄ        0\n",
       "üíµ        0\n",
       "üìß        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = df.dot(word_vec.transpose())\n",
    "matches.sort_values(0,ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simplified example we are embedding our elements (words and emoji) in a nine-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(df[0]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ú® üí™ üî™'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import alethio\n",
    "\n",
    "alethio.generate_answer('How can I prepare for the coming apocalypse?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
